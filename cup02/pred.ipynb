{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
    "                 \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \n",
    "                 \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \n",
    "                 \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            #tf.config.experimental.set_per_process_memory_fraction(0.75)\n",
    "            tf.config.experimental.set_memory_growth(gpu, False)\n",
    "            #tf.config.gpu.set_per_process_memory_fraction(0.4)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, InputLayer, Dropout, LayerNormalization, Flatten, Dense, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# common params\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 1\n",
    "NUM_CLASSES = 20\n",
    "MAX_OBJECTS_PER_IMAGE = 20\n",
    "\n",
    "# dataset params\n",
    "DATA_PATH = './dataset/VOCdevkit_train/VOC2007/pascal_voc_training_data.txt'\n",
    "IMAGE_DIR = './dataset/VOCdevkit_train/VOC2007/JPEGImages/'\n",
    "\n",
    "# model params\n",
    "CELL_SIZE = 7\n",
    "BOXES_PER_CELL = 2\n",
    "OBJECT_SCALE = 1\n",
    "NOOBJECT_SCALE = 0.5\n",
    "CLASS_SCALE = 1\n",
    "COORD_SCALE = 5\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "#x = conv_leaky_relu(img_inputs, 64, 7, 2)\n",
    "x = Conv2D(64, activation='relu', padding='same', kernel_size=(3, 3), strides=(1, 1))(img_inputs)\n",
    "x = Conv2D(64, activation='relu', padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(128, data_format=\"channels_last\",  activation='relu', \n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = Conv2D(128, data_format=\"channels_last\",  activation='relu', \n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(256, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = Conv2D(256, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = Conv2D(256, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "#x = Dropout(0.25)(x)\n",
    "x = Conv2D(125, use_bias=True, data_format=\"channels_last\", activation='relu',\n",
    "       padding='same', kernel_size=(1, 1), strides=(1, 1), kernel_initializer='random_uniform')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "x = LeakyReLU(0.1)(x)\n",
    "outputs = Dense(1470, activation='relu', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "\n",
    "YOLO = keras.Model(inputs=img_inputs, outputs=outputs, name=\"YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outputs(outputs):\n",
    "    \"\"\"\n",
    "    Process YOLO outputs into bou\n",
    "    \"\"\"\n",
    "\n",
    "    n1 = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "    n2 = n1 + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "    class_probs = np.reshape(outputs[:, 0:n1], (-1, 7, 7, 20))\n",
    "    scales = np.reshape(outputs[:, n1:n2], (-1, 7, 7, 2))\n",
    "    boxes = np.reshape(outputs[:, n2:], (-1, 7, 7, 2*4))\n",
    "    predicts = np.concatenate([class_probs, scales, boxes], 3)\n",
    "\n",
    "    p_classes = predicts[0, :, :, 0:20]\n",
    "    C = predicts[0, :, :, 20:22]\n",
    "    coordinate = predicts[0, :, :, 22:]\n",
    "\n",
    "    p_classes = np.reshape(p_classes, (CELL_SIZE, CELL_SIZE, 1, 20))\n",
    "    C = np.reshape(C, (CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 1))\n",
    "\n",
    "    P = C * p_classes\n",
    "    #P's shape [7, 7, 2, 20]\n",
    "    #print P[5,1, 0, :]\n",
    "\n",
    "    #choose the most confidence one\n",
    "    max_conf = np.max(P)\n",
    "    index = np.argmax(P)\n",
    "\n",
    "    index = np.unravel_index(index, P.shape)\n",
    "\n",
    "    class_num = index[3]\n",
    "\n",
    "    coordinate = np.reshape(coordinate, \n",
    "                            (CELL_SIZE, \n",
    "                             CELL_SIZE,\n",
    "                             BOXES_PER_CELL, \n",
    "                             4))\n",
    "\n",
    "    max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "    xcenter = max_coordinate[0]\n",
    "    ycenter = max_coordinate[1]\n",
    "    w = max_coordinate[2]\n",
    "    h = max_coordinate[3]\n",
    "\n",
    "    xcenter = (index[1] + xcenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "    ycenter = (index[0] + ycenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "\n",
    "    w = w * IMAGE_SIZE\n",
    "    h = h * IMAGE_SIZE\n",
    "\n",
    "    xmin = xcenter - w/2.0\n",
    "    ymin = ycenter - h/2.0\n",
    "\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "\n",
    "    return xmin, ymin, xmax, ymax, class_num, max_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_files = open('./dataset/pascal_voc_testing_data.txt')\n",
    "test_img_dir = './dataset/VOCdevkit_test/VOC2007/JPEGImages/'\n",
    "test_images = []\n",
    "\n",
    "for line in test_img_files:\n",
    "    line = line.strip()\n",
    "    ss = line.split(' ')\n",
    "    test_images.append(ss[0])\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "\n",
    "def load_img_data(image_name):\n",
    "    image_file = tf.io.read_file(test_img_dir+image_name)\n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "    h = tf.shape(image)[0]\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image = (image/255) * 2 - 1\n",
    "\n",
    "    return image_name, image, h, w\n",
    "\n",
    "test_dataset = test_dataset.map(load_img_data, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None,), (None, 448, 448, 3), (None,), (None,)), types: (tf.string, tf.float32, tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1b867967b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(net=YOLO)\n",
    "ckpt.restore('./ckpts/YOLO/yolo-37')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def prediction_step(img):\n",
    "    return YOLO(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('./test_prediction.txt', 'w')\n",
    "\n",
    "for img_name, test_img, img_h, img_w in test_dataset:\n",
    "    batch_num = img_name.shape[0]\n",
    "    for i in range(batch_num):\n",
    "        xmin, ymin, xmax, ymax, class_num, conf = process_outputs(prediction_step(test_img[i:i+1]))\n",
    "        xmin, ymin, xmax, ymax = xmin*(img_w[i:i+1]/IMAGE_SIZE), ymin*(img_h[i:i+1]/IMAGE_SIZE), xmax*(img_w[i:i+1]/IMAGE_SIZE), ymax*(img_h[i:i+1]/IMAGE_SIZE)\n",
    "\n",
    "        #img filename, xmin, ymin, xmax, ymax, class, confidence\n",
    "        output_file.write(img_name[i:i+1].numpy()[0].decode('ascii')+\" %d %d %d %d %d %f\\n\" %(xmin, ymin, xmax, ymax, class_num, conf))\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Evalutation\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './evaluate')\n",
    "import evaluate\n",
    "#evaluate.evaluate(\"input prediction file name\", \"desire output csv file name\")\n",
    "evaluate.evaluate('./test_prediction.txt', './output_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
