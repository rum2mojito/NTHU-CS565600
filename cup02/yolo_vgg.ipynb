{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
    "                 \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \n",
    "                 \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \n",
    "                 \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000005.jpg 263 211 324 339 8 165 264 253 372 8 5 244 67 374 8 241 194 295 299 8 277 186 312 220 8\n",
      "000007.jpg 141 50 500 330 6\n",
      "000009.jpg 69 172 270 330 12 150 141 229 284 14 285 201 327 331 14 258 198 297 329 14\n",
      "000012.jpg 156 97 351 270 6\n",
      "000016.jpg 92 72 305 473 1\n",
      "000017.jpg 185 62 279 199 14 90 78 403 336 12\n"
     ]
    }
   ],
   "source": [
    "training_data_file = open(\"./dataset/VOCdevkit_train/VOC2007/pascal_voc_training_data.txt\", \"r\")\n",
    "for i, line in enumerate(training_data_file):\n",
    "    if i >5:\n",
    "        break\n",
    "    line = line.strip()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common params\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 6\n",
    "NUM_CLASSES = 20\n",
    "MAX_OBJECTS_PER_IMAGE = 20\n",
    "\n",
    "# dataset params\n",
    "DATA_PATH = './dataset/VOCdevkit_train/VOC2007/pascal_voc_training_data.txt'\n",
    "IMAGE_DIR = './dataset/VOCdevkit_train/VOC2007/JPEGImages/'\n",
    "\n",
    "# model params\n",
    "CELL_SIZE = 7\n",
    "BOXES_PER_CELL = 2\n",
    "OBJECT_SCALE = 1\n",
    "NOOBJECT_SCALE = 0.5\n",
    "CLASS_SCALE = 1\n",
    "COORD_SCALE = 5\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    \"\"\"\n",
    "    Load pascalVOC 2007 dataset and creates an input pipeline ready to be fed into a model.\n",
    "    - Reshapes images into 448 x 448\n",
    "    - converts [0 1] to [-1 1]\n",
    "    - shuffles the input\n",
    "    - builds batches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.image_names = []\n",
    "        self.record_list = []\n",
    "        self.object_num_list = []\n",
    "        # filling the record_list\n",
    "        input_file = open(DATA_PATH, 'r')\n",
    "\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            ss = line.split(' ')\n",
    "            self.image_names.append(ss[0])\n",
    "\n",
    "            self.record_list.append([float(num) for num in ss[1:]])\n",
    "\n",
    "            self.object_num_list.append(min(len(self.record_list[-1])//5, MAX_OBJECTS_PER_IMAGE))\n",
    "            if len(self.record_list[-1]) < MAX_OBJECTS_PER_IMAGE*5:\n",
    "                self.record_list[-1] = self.record_list[-1] +\\\n",
    "                [0., 0., 0., 0., 0.]*\\\n",
    "                (MAX_OBJECTS_PER_IMAGE-len(self.record_list[-1])//5)\n",
    "            elif len(self.record_list[-1]) > MAX_OBJECTS_PER_IMAGE*5:\n",
    "                self.record_list[-1] = self.record_list[-1][:MAX_OBJECTS_PER_IMAGE*5]\n",
    "\n",
    "    def _data_preprocess(self, image_name, raw_labels, object_num):\n",
    "        image_file = tf.io.read_file(IMAGE_DIR+image_name)\n",
    "        image = tf.io.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "        h = tf.shape(image)[0]\n",
    "        w = tf.shape(image)[1]\n",
    "\n",
    "        width_rate = IMAGE_SIZE * 1.0 / tf.cast(w, tf.float32) \n",
    "        height_rate = IMAGE_SIZE * 1.0 / tf.cast(h, tf.float32) \n",
    "\n",
    "        image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "        #image = (image/255) * 2 - 1\n",
    "        image = tf.image.per_image_standardization(image)\n",
    "\n",
    "        raw_labels = tf.cast(tf.reshape(raw_labels, [-1, 5]), tf.float32)\n",
    "\n",
    "        xmin = raw_labels[:, 0]\n",
    "        ymin = raw_labels[:, 1]\n",
    "        xmax = raw_labels[:, 2]\n",
    "        ymax = raw_labels[:, 3]\n",
    "        class_num = raw_labels[:, 4]\n",
    "\n",
    "        xcenter = (xmin + xmax) * 1.0 / 2.0 * width_rate\n",
    "        ycenter = (ymin + ymax) * 1.0 / 2.0 * height_rate\n",
    "\n",
    "        box_w = (xmax - xmin) * width_rate\n",
    "        box_h = (ymax - ymin) * height_rate\n",
    "\n",
    "        labels = tf.stack([xcenter, ycenter, box_w, box_h, class_num], axis = 1)\n",
    "\n",
    "        return image, labels, tf.cast(object_num, tf.int32)\n",
    "\n",
    "    def generate(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.image_names, \n",
    "                                                      np.array(self.record_list), \n",
    "                                                      np.array(self.object_num_list)))\n",
    "        dataset = dataset.map(self._data_preprocess, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "        #dataset = dataset.shuffle(10)\n",
    "        dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LayerNormalization, Flatten, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, InputLayer, Dropout, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 448, 448, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 448, 448, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 448, 448, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 224, 224, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 224, 224, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 112, 112, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 112, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 112, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 56, 56, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 56, 56, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 56, 56, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "x = Conv2D(64, activation='relu', padding='same', kernel_size=(3, 3), strides=(1, 1))(img_inputs)\n",
    "x = Conv2D(64, activation='relu', padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(128, data_format=\"channels_last\",  activation='relu', \n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = Conv2D(128, data_format=\"channels_last\",  activation='relu', \n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(256, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = Conv2D(256, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = Conv2D(256, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = Conv2D(512, data_format=\"channels_last\",  activation='relu',\n",
    "       padding='same', kernel_size=(3, 3), strides=(1, 1))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "# Block6\n",
    "for _ in range(0,2):\n",
    "    x = Conv2D(1024, (3, 3), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "x = LeakyReLU(0.1)(x)\n",
    "outputs = Dense(1470, activation='relu', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "\n",
    "YOLO = keras.Model(inputs=img_inputs, outputs=outputs, name=\"YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg19 = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "# img_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "# x = vgg19.layers[1](img_inputs)\n",
    "# x = LeakyReLU(alpha=0.1)(x)\n",
    "# x = vgg19.layers[2](x)\n",
    "# x = LeakyReLU(alpha=0.1)(x)\n",
    "# x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "# # Block2\n",
    "# for i in range(4, 6):\n",
    "#     x = vgg19.layers[i](x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "# x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "# # Block3\n",
    "# for i in range(7, 10):\n",
    "#     x = vgg19.layers[i](x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "# x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "# # Block4\n",
    "# for i in range(11, 14):\n",
    "#     x = vgg19.layers[i](x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "# x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "# # Block5\n",
    "# for i in range(15, 18):\n",
    "#     x = vgg19.layers[i](x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "# x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "# # Block6\n",
    "# for _ in range(0,2):\n",
    "#     x = Conv2D(1024, (3, 3), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(4096, kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "# x = layers.LeakyReLU(0.1)(x)\n",
    "# outputs = layers.Dense(1470, activation='relu', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "\n",
    "# YOLO = keras.Model(inputs=img_inputs, outputs=outputs, name=\"YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base boxes (for loss calculation)\n",
    "base_boxes = np.zeros([CELL_SIZE, CELL_SIZE, 4])\n",
    "\n",
    "#for each cell\n",
    "for y in range(CELL_SIZE):\n",
    "    for x in range(CELL_SIZE):\n",
    "        base_boxes[y, x, :] = [IMAGE_SIZE / CELL_SIZE * x, IMAGE_SIZE / CELL_SIZE * y, 0, 0]\n",
    "\n",
    "base_boxes = np.tile(np.resize(base_boxes, [CELL_SIZE, CELL_SIZE, 1, 4]), [1, 1, BOXES_PER_CELL, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(predicts, labels, objects_num):\n",
    "    \"\"\"\n",
    "    calculate loss\n",
    "    Args:\n",
    "        predict: 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\n",
    "        labels : [max_objects, 5]  (x_center, y_center, w, h, class)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Add Loss to all the trainable variables\n",
    "    Args:\n",
    "        predicts: 4-D tensor [batch_size, cell_size, cell_size, 5 * boxes_per_cell]\n",
    "        ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n",
    "        labels  : 3-D tensor of [batch_size, max_objects, 5]\n",
    "        objects_num: 1-D tensor [batch_size]\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = predicts.shape[0]\n",
    "    loss = 0.\n",
    "\n",
    "    for i in tf.range(batch_size):\n",
    "        predict = predicts[i, :, :, :]\n",
    "        label = labels[i, :, :]\n",
    "        object_num = objects_num[i]\n",
    "\n",
    "        for j in tf.range(object_num):\n",
    "            results = losses_calculation(predict, label[j:j+1, :])\n",
    "            loss = loss + results\n",
    "\n",
    "    return loss/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(boxes1, boxes2):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "      boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "      boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "\n",
    "    Return:\n",
    "      iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    \"\"\"\n",
    "\n",
    "    #boxes1 : [4(xmin, ymin, xmax, ymax), cell_size, cell_size, boxes_per_cell]\n",
    "    boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                      boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "\n",
    "    #boxes1 : [cell_size, cell_size, boxes_per_cell, 4(xmin, ymin, xmax, ymax)]\n",
    "    boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "\n",
    "    boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                      boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "\n",
    "    #calculate the left up point of boxes' overlap area\n",
    "    lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "    #calculate the right down point of boxes overlap area\n",
    "    rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "\n",
    "    #intersection\n",
    "    intersection = rd - lu \n",
    "\n",
    "    #the size of the intersection area\n",
    "    inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "\n",
    "    mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "\n",
    "    #if intersection is negative, then the boxes don't overlap\n",
    "    inter_square = mask * inter_square\n",
    "\n",
    "    #calculate the boxs1 square and boxs2 square\n",
    "    square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "    square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "\n",
    "    return inter_square/(square1 + square2 - inter_square + 1e-6)\n",
    "\n",
    "def losses_calculation(predict, label):\n",
    "    \"\"\"\n",
    "    calculate loss\n",
    "    Args:\n",
    "      predict: 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\n",
    "      label : [1, 5]  (x_center, y_center, w, h, class)\n",
    "    \"\"\"\n",
    "    label = tf.reshape(label, [-1])\n",
    "\n",
    "    #calculate objects tensor [CELL_SIZE, CELL_SIZE]\n",
    "    min_x = (label[0] - label[2] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "    max_x = (label[0] + label[2] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "\n",
    "    min_y = (label[1] - label[3] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "    max_y = (label[1] + label[3] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "\n",
    "    min_x = tf.floor(min_x)\n",
    "    min_y = tf.floor(min_y)\n",
    "\n",
    "    max_x = tf.minimum(tf.math.ceil(max_x), CELL_SIZE)\n",
    "    max_y = tf.minimum(tf.math.ceil(max_y), CELL_SIZE)\n",
    "\n",
    "    temp = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\n",
    "    objects = tf.ones(temp, tf.float32)\n",
    "\n",
    "    temp = tf.cast(tf.stack([min_y, CELL_SIZE - max_y, min_x, CELL_SIZE - max_x]), tf.int32)\n",
    "    temp = tf.reshape(temp, (2, 2))\n",
    "    objects = tf.pad(objects, temp, \"CONSTANT\")\n",
    "\n",
    "    #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "    #calculate responsible tensor [CELL_SIZE, CELL_SIZE]\n",
    "    center_x = label[0] / (IMAGE_SIZE / CELL_SIZE)\n",
    "    center_x = tf.floor(center_x)\n",
    "\n",
    "    center_y = label[1] / (IMAGE_SIZE / CELL_SIZE)\n",
    "    center_y = tf.floor(center_y)\n",
    "\n",
    "    response = tf.ones([1, 1], tf.float32)\n",
    "\n",
    "    temp = tf.cast(tf.stack([center_y, CELL_SIZE - center_y - 1, \n",
    "                             center_x, CELL_SIZE - center_x - 1]), \n",
    "                   tf.int32)\n",
    "#     tmp = tf.stack([center_y, CELL_SIZE - center_y - 1,\n",
    "#                     center_x, CELL_SIZE - center_x - 1])\n",
    "    temp = tf.reshape(temp, (2, 2))\n",
    "    response = tf.pad(response, temp, \"CONSTANT\")\n",
    "    #objects = response\n",
    "\n",
    "    #calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    predict_boxes = predict[:, :, NUM_CLASSES + BOXES_PER_CELL:]\n",
    "\n",
    "    predict_boxes = tf.reshape(predict_boxes, [CELL_SIZE, \n",
    "                                               CELL_SIZE, \n",
    "                                               BOXES_PER_CELL, 4])\n",
    "\n",
    "    predict_boxes = predict_boxes * [IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE, IMAGE_SIZE]\n",
    "\n",
    "    #if there's no predict_box in that cell, then the base_boxes will be calcuated with label and got iou equals 0\n",
    "    predict_boxes = base_boxes + predict_boxes\n",
    "\n",
    "    iou_predict_truth = iou(predict_boxes, label[0:4])\n",
    "    #calculate C [cell_size, cell_size, boxes_per_cell]\n",
    "    C = iou_predict_truth * tf.reshape(response, [CELL_SIZE, CELL_SIZE, 1])\n",
    "\n",
    "    #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    I = iou_predict_truth * tf.reshape(response, (CELL_SIZE, CELL_SIZE, 1))\n",
    "\n",
    "    max_I = tf.reduce_max(I, 2, keepdims=True)\n",
    "\n",
    "    I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (CELL_SIZE, CELL_SIZE, 1))\n",
    "\n",
    "    #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    no_I = tf.ones_like(I, dtype=tf.float32) - I\n",
    "\n",
    "    p_C = predict[:, :, NUM_CLASSES:NUM_CLASSES + BOXES_PER_CELL]\n",
    "\n",
    "    #calculate truth x, y, sqrt_w, sqrt_h 0-D\n",
    "    x = label[0]\n",
    "    y = label[1]\n",
    "\n",
    "    sqrt_w = tf.sqrt(tf.abs(label[2]))\n",
    "    sqrt_h = tf.sqrt(tf.abs(label[3]))\n",
    "\n",
    "    #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    p_x = predict_boxes[:, :, :, 0]\n",
    "    p_y = predict_boxes[:, :, :, 1]\n",
    "\n",
    "    #p_sqrt_w = tf.sqrt(tf.abs(predict_boxes[:, :, :, 2])) * ((tf.cast(predict_boxes[:, :, :, 2] > 0, tf.float32) * 2) - 1)\n",
    "    #p_sqrt_h = tf.sqrt(tf.abs(predict_boxes[:, :, :, 3])) * ((tf.cast(predict_boxes[:, :, :, 3] > 0, tf.float32) * 2) - 1)\n",
    "    #p_sqrt_w = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 2]))\n",
    "    #p_sqrt_h = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 3]))\n",
    "    #p_sqrt_w = predict_boxes[:, :, :, 2]\n",
    "    #p_sqrt_h = predict_boxes[:, :, :, 3]\n",
    "    p_sqrt_w = tf.sqrt(tf.minimum(IMAGE_SIZE * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "    p_sqrt_h = tf.sqrt(tf.minimum(IMAGE_SIZE * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "\n",
    "    #calculate truth p 1-D tensor [NUM_CLASSES]\n",
    "    P = tf.one_hot(tf.cast(label[4], tf.int32), NUM_CLASSES, dtype=tf.float32)\n",
    "\n",
    "    #calculate predict p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\n",
    "    p_P = predict[:, :, 0:NUM_CLASSES]\n",
    "\n",
    "    #class_loss\n",
    "    class_loss = tf.nn.l2_loss(tf.reshape(objects, (CELL_SIZE, CELL_SIZE, 1)) * (p_P - P)) * CLASS_SCALE\n",
    "    #class_loss = tf.nn.l2_loss(tf.reshape(response, (CELL_SIZE, CELL_SIZE, 1)) * (p_P - P)) * CLASS_SCALE\n",
    "\n",
    "    #object_loss\n",
    "    object_loss = tf.nn.l2_loss(I * (p_C - C)) * OBJECT_SCALE\n",
    "    #object_loss = tf.nn.l2_loss(I * (p_C - (C + 1.0)/2.0)) * OBJECT_SCALE\n",
    "\n",
    "    #noobject_loss\n",
    "    #noobject_loss = tf.nn.l2_loss(no_I * (p_C - C)) * NOOBJECT_SCALE\n",
    "    noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * NOOBJECT_SCALE\n",
    "\n",
    "    #coord_loss\n",
    "    coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(IMAGE_SIZE/CELL_SIZE)) +\n",
    "                 tf.nn.l2_loss(I * (p_y - y)/(IMAGE_SIZE/CELL_SIZE)) +\n",
    "                 tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/IMAGE_SIZE +\n",
    "                 tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/IMAGE_SIZE) * COORD_SCALE\n",
    "\n",
    "    return class_loss + object_loss + noobject_loss + coord_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetGenerator().generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "train_loss_metric = tf.keras.metrics.Mean(name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKP_DIR = \"./ckpts/YOLO_VGG\"\n",
    "init_epoch = 0\n",
    "\n",
    "ckpt = tf.train.Checkpoint(epoch=tf.Variable(0), net=YOLO)\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, './ckpts/YOLO', max_to_keep=3,\n",
    "                                     checkpoint_name='yolo')\n",
    "\n",
    "ckp = tf.train.latest_checkpoint(CKP_DIR)\n",
    "if ckp:\n",
    "    ckpt.restore(ckp)\n",
    "    init_epoch = int(ckp.split('-')[-1]) + 1\n",
    "    print(f'Resume training from epoch {init_epoch-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, labels, objects_num):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = YOLO(image)\n",
    "        n1 = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "        n2 = n1 + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "        class_probs = tf.reshape(outputs[:, 0:n1], (-1, 7, 7, 20))\n",
    "        scales = tf.reshape(outputs[:, n1:n2], (-1, 7, 7, 2))\n",
    "        boxes = tf.reshape(outputs[:, n2:], (-1, 7, 7, 2*4))\n",
    "        predicts = tf.concat([class_probs, scales, boxes], 3)\n",
    "\n",
    "        loss = yolo_loss(predicts, labels, objects_num)\n",
    "        train_loss_metric(loss)\n",
    "\n",
    "    grads = tape.gradient(loss, YOLO.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, YOLO.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 2487\n",
    "print(\"{}, start training.\".format(datetime.now()))\n",
    "#steps_per_epoch = dataset.size()\n",
    "for i in range(init_epoch, EPOCHS):\n",
    "    train_loss_metric.reset_states()\n",
    "    ckpt.epoch.assign_add(1)\n",
    "\n",
    "    for idx, (image, labels, objects_num) in enumerate(dataset):\n",
    "        #print(idx)\n",
    "        train_step(image, labels, objects_num)\n",
    "        print(f'{datetime.now()}, Epoch {i+1}: step: {idx}/{steps_per_epoch}: loss {train_loss_metric.result():.5f}', end='\\r')\n",
    "\n",
    "    print(\"{}, Epoch {}: loss {:.2f}\".format(datetime.now(), i+1, train_loss_metric.result()))\n",
    "\n",
    "    save_path = manager.save()\n",
    "    print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.epoch), save_path))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outputs(outputs):\n",
    "    \"\"\"\n",
    "    Process YOLO outputs into bou\n",
    "    \"\"\"\n",
    "\n",
    "    n1 = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "    n2 = n1 + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "    class_probs = np.reshape(outputs[:, 0:n1], (-1, 7, 7, 20))\n",
    "    scales = np.reshape(outputs[:, n1:n2], (-1, 7, 7, 2))\n",
    "    boxes = np.reshape(outputs[:, n2:], (-1, 7, 7, 2*4))\n",
    "    predicts = np.concatenate([class_probs, scales, boxes], 3)\n",
    "\n",
    "    p_classes = predicts[0, :, :, 0:20]\n",
    "    C = predicts[0, :, :, 20:22]\n",
    "    coordinate = predicts[0, :, :, 22:]\n",
    "\n",
    "    p_classes = np.reshape(p_classes, (CELL_SIZE, CELL_SIZE, 1, 20))\n",
    "    C = np.reshape(C, (CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 1))\n",
    "\n",
    "    P = C * p_classes\n",
    "    #P's shape [7, 7, 2, 20]\n",
    "    #print P[5,1, 0, :]\n",
    "\n",
    "    #choose the most confidence one\n",
    "    max_conf = np.max(P)\n",
    "    index = np.argmax(P)\n",
    "\n",
    "    index = np.unravel_index(index, P.shape)\n",
    "\n",
    "    class_num = index[3]\n",
    "\n",
    "    coordinate = np.reshape(coordinate, \n",
    "                            (CELL_SIZE, \n",
    "                             CELL_SIZE,\n",
    "                             BOXES_PER_CELL, \n",
    "                             4))\n",
    "\n",
    "    max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "    xcenter = max_coordinate[0]\n",
    "    ycenter = max_coordinate[1]\n",
    "    w = max_coordinate[2]\n",
    "    h = max_coordinate[3]\n",
    "\n",
    "    xcenter = (index[1] + xcenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "    ycenter = (index[0] + ycenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "\n",
    "    w = w * IMAGE_SIZE\n",
    "    h = h * IMAGE_SIZE\n",
    "\n",
    "    xmin = xcenter - w/2.0\n",
    "    ymin = ycenter - h/2.0\n",
    "\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "\n",
    "    return xmin, ymin, xmax, ymax, class_num, max_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_files = open('./dataset/pascal_voc_testing_data.txt')\n",
    "test_img_dir = './dataset/VOCdevkit_test/VOC2007/JPEGImages/'\n",
    "test_images = []\n",
    "\n",
    "for line in test_img_files:\n",
    "    line = line.strip()\n",
    "    ss = line.split(' ')\n",
    "    test_images.append(ss[0])\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "\n",
    "def load_img_data(image_name):\n",
    "    image_file = tf.io.read_file(test_img_dir+image_name)\n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "    h = tf.shape(image)[0]\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "\n",
    "    return image_name, image, h, w\n",
    "\n",
    "test_dataset = test_dataset.map(load_img_data, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(net=YOLO)\n",
    "ckpt.restore('./ckpts/YOLO/yolo-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def prediction_step(img):\n",
    "    return YOLO(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('./test_prediction.txt', 'w')\n",
    "\n",
    "for img_name, test_img, img_h, img_w in test_dataset:\n",
    "    print(img_name)\n",
    "    y_pred = prediction_step(test_img)\n",
    "    xmin, ymin, xmax, ymax, class_num, conf = process_outputs(y_pred)\n",
    "    xmin, ymin, xmax, ymax = xmin*(img_w/IMAGE_SIZE), ymin*(img_h/IMAGE_SIZE), xmax*(img_w/IMAGE_SIZE), ymax*(img_h/IMAGE_SIZE)\n",
    "\n",
    "    #img filename, xmin, ymin, xmax, ymax, class, confidence\n",
    "    output_file.write(img_name.numpy()[0].decode('ascii')+\" %d %d %d %d %d %f\\n\" %(xmin, ymin, xmax, ymax, class_num, conf))\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './evaluate')\n",
    "import evaluate\n",
    "#evaluate.evaluate(\"input prediction file name\", \"desire output csv file name\")\n",
    "evaluate.evaluate('./test_prediction.txt', './output_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img = cv2.imread('./VOCdevkit_test/VOC2007/JPEGImages/000002.jpg')\n",
    "resized_img = cv2.resize(np_img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "np_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "resized_img = np_img\n",
    "np_img = np_img.astype(np.float32)\n",
    "np_img = np_img / 255.0 * 2 - 1\n",
    "np_img = np.reshape(np_img, (1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "y_pred = YOLO(np_img)\n",
    "xmin, ymin, xmax, ymax, class_num, conf = process_outputs(y_pred)\n",
    "class_name = classes_name[class_num]\n",
    "cv2.rectangle(resized_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 255), 3)\n",
    "cv2.putText(resized_img, class_name, (0, 200), 2, 1.5, (0, 255, 255), 2)\n",
    "\n",
    "plt.imshow(resized_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
