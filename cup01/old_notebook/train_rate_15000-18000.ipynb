{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, itertools, csv\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pytrends.request import TrendReq\n",
    "from datetime import *\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('./data/train.csv')\n",
    "dataset.head()\n",
    "\n",
    "start = 15121\n",
    "end = 18002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yuwei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def get_category(text: str) -> list:\n",
    "    res = list()\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    cats = soup.find_all('a', {'href': re.compile('/category/*')})\n",
    "    for cat in cats:\n",
    "        res.append(cat.get_text().lower())\n",
    "    lem = WordNetLemmatizer()\n",
    "    res = [lem.lemmatize(word) for word in res if not word in  \n",
    "        stop_words]\n",
    "    return list(set(res))\n",
    "\n",
    "res = []\n",
    "for i in range(0, dataset.shape[0]):\n",
    "    res.append(get_category(dataset['Page content'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "from datetime import *\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxy_list():\n",
    "    proxies = requests.get(\"https://proxy.rudnkh.me/txt\")\n",
    "    # print(res.text)\n",
    "    proxy_list = [\"http://\"+proxy for proxy in proxies.text.split(\"\\n\")]\n",
    "    proxy_list.remove(\"http://\")\n",
    "    random.shuffle(proxy_list)\n",
    "    #print(\"Candidate: \" + str(proxy_list))\n",
    "    return proxy_list\n",
    "\n",
    "# Test\n",
    "# print(get_proxy_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend(word: str, t_start: str, t_end: str) -> list:\n",
    "    search = word +\" \"+ t_start +\" \"+ t_end\n",
    "    print(colored(search, \"yellow\"))\n",
    "    g_trends = TrendReq(tz=360, timeout=(10,25), proxies=get_proxy_list(), retries=4, backoff_factor=0.1)\n",
    "#     g_trends = TrendReq(hl='en-US', tz=360)\n",
    "    g_trends.build_payload([word], timeframe = t_start+' '+t_end, geo='', gprop='')\n",
    "    trend = g_trends.interest_over_time()\n",
    "    if trend.size > 0:\n",
    "        trend.columns = ['0', '1']\n",
    "        #trend = trend.columns.get_loc()\n",
    "        # trend.head()\n",
    "        return trend['0'].values\n",
    "    else: \n",
    "        print(word+\" request fail.\")\n",
    "        return []\n",
    "\n",
    "# test\n",
    "# print(get_trend('NFV', '2013-06-20', '2013-07-20'))\n",
    "# print(get_trend('NFV', '2013-06-20', '2013-07-20'))\n",
    "# print(np.mean(get_trend('NFV', '2013-06-20', '2013-07-20'), axis=0))\n",
    "# print(np.std(get_trend('NFV', '2013-06-20', '2013-07-20'), axis=0, ddof=1))\n",
    "# print(np.std([1, 2, 3], ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(text: str) -> datetime:\n",
    "    soup = BeautifulSoup(text)\n",
    "    selector = \"time\"\n",
    "    date = [i.text for i in soup.select(selector)][0]\n",
    "    date = date.split()\n",
    "    date = str(date[0] + ' ' + date[1])\n",
    "\n",
    "    d = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSearch: tornado alley\u001b[0m\n",
      "\u001b[33mtornado alley 2014-06-12 2014-07-11\u001b[0m\n",
      "\u001b[31mSearch: tornado\u001b[0m\n",
      "\u001b[33mtornado 2014-06-12 2014-07-11\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /?geo=US (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\n",
      "Retry step: 0\n",
      "\u001b[33mtornado 2014-06-12 2014-07-11\u001b[0m\n",
      "\u001b[31mSearch: tornado outbreak\u001b[0m\n",
      "\u001b[33mtornado outbreak 2014-06-12 2014-07-11\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "Proxy error. Changing IP\n",
      "\u001b[31mSearch: severe weather\u001b[0m\n",
      "\u001b[33msevere weather 2014-06-12 2014-07-11\u001b[0m\n",
      "\u001b[31mSearch: climate\u001b[0m\n",
      "\u001b[33mclimate 2014-06-12 2014-07-11\u001b[0m\n",
      "The request failed: Google returned a response with code 429.\n",
      "Retry step: 0\n",
      "\u001b[33mclimate 2014-06-12 2014-07-11\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "Proxy error. Changing IP\n",
      "\u001b[31mSearch: tornado wall\u001b[0m\n",
      "\u001b[33mtornado wall 2014-06-12 2014-07-11\u001b[0m\n",
      "\u001b[31mSearch: u.s.\u001b[0m\n",
      "\u001b[33mu.s. 2014-06-12 2014-07-11\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "Proxy error. Changing IP\n",
      "\u001b[31mSearch: world\u001b[0m\n",
      "\u001b[33mworld 2014-06-12 2014-07-11\u001b[0m\n",
      "[0.9663526244952894]\n",
      "\u001b[32m18002 done\u001b[0m\n",
      "\u001b[31mSearch: photography\u001b[0m\n",
      "\u001b[33mphotography 2013-05-27 2013-06-25\u001b[0m\n",
      "\u001b[31mSearch: celebrity\u001b[0m\n",
      "\u001b[33mcelebrity 2013-05-27 2013-06-25\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "\u001b[31mSearch: twitter\u001b[0m\n",
      "\u001b[33mtwitter 2013-05-27 2013-06-25\u001b[0m\n",
      "\u001b[31mSearch: watercooler\u001b[0m\n",
      "\u001b[33mwatercooler 2013-05-27 2013-06-25\u001b[0m\n",
      "\u001b[31mSearch: television\u001b[0m\n",
      "\u001b[33mtelevision 2013-05-27 2013-06-25\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /?geo=US (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\n",
      "Retry step: 0\n",
      "\u001b[33mtelevision 2013-05-27 2013-06-25\u001b[0m\n",
      "\u001b[31mSearch: photobomb\u001b[0m\n",
      "\u001b[33mphotobomb 2013-05-27 2013-06-25\u001b[0m\n",
      "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /?geo=US (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\n",
      "Retry step: 0\n",
      "\u001b[33mphotobomb 2013-05-27 2013-06-25\u001b[0m\n",
      "\u001b[31mSearch: bob saget\u001b[0m\n",
      "\u001b[33mbob saget 2013-05-27 2013-06-25\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "[0.9663526244952894, 1.072570725707257]\n",
      "\u001b[32m18003 done\u001b[0m\n",
      "\u001b[31mSearch: world\u001b[0m\n",
      "\u001b[33mworld 2014-01-29 2014-02-27\u001b[0m\n",
      "\u001b[31mSearch: time warner cable\u001b[0m\n",
      "\u001b[33mtime warner cable 2014-01-29 2014-02-27\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "Proxy error. Changing IP\n",
      "\u001b[31mSearch: federal communications commission\u001b[0m\n",
      "\u001b[33mfederal communications commission 2014-01-29 2014-02-27\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "\u001b[31mSearch: net neutrality\u001b[0m\n",
      "\u001b[33mnet neutrality 2014-01-29 2014-02-27\u001b[0m\n",
      "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /?geo=US (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\n",
      "Retry step: 0\n",
      "\u001b[33mnet neutrality 2014-01-29 2014-02-27\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /?geo=US (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\n",
      "Retry step: 1\n",
      "\u001b[33mnet neutrality 2014-01-29 2014-02-27\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /?geo=US (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000017705BB8E10>, 'Connection to 103.95.40.211 timed out. (connect timeout=10)'))\n",
      "Retry step: 2\n",
      "\u001b[33mnet neutrality 2014-01-29 2014-02-27\u001b[0m\n",
      "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /?geo=US (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\n",
      "Retry step: 3\n",
      "\u001b[33mnet neutrality 2014-01-29 2014-02-27\u001b[0m\n",
      "\u001b[31mSearch: u.s.\u001b[0m\n",
      "\u001b[33mu.s. 2014-01-29 2014-02-27\u001b[0m\n",
      "\u001b[31mSearch: comcast\u001b[0m\n",
      "\u001b[33mcomcast 2014-01-29 2014-02-27\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "Proxy error. Changing IP\n",
      "\u001b[31mSearch: google fiber\u001b[0m\n",
      "\u001b[33mgoogle fiber 2014-01-29 2014-02-27\u001b[0m\n",
      "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /?geo=US (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\n",
      "Retry step: 0\n",
      "\u001b[33mgoogle fiber 2014-01-29 2014-02-27\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "\u001b[31mSearch: medium\u001b[0m\n",
      "\u001b[33mmedium 2014-01-29 2014-02-27\u001b[0m\n",
      "\u001b[31mSearch: internet freedom\u001b[0m\n",
      "\u001b[33minternet freedom 2014-01-29 2014-02-27\u001b[0m\n",
      "Proxy error. Changing IP\n",
      "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /?geo=US (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\n",
      "Retry step: 0\n",
      "\u001b[33minternet freedom 2014-01-29 2014-02-27\u001b[0m\n",
      "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22internet+freedom%22%2C+%22time%22%3A+%222014-01-29+2014-02-27%22%2C+%22geo%22%3A+%22%22%7D%5D%2C+%22category%22%3A+0%2C+%22property%22%3A+%22%22%7D (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response',)))\n",
      "Retry step: 1\n",
      "\u001b[33minternet freedom 2014-01-29 2014-02-27\u001b[0m\n",
      "\u001b[31mSearch: tech policy\u001b[0m\n",
      "\u001b[33mtech policy 2014-01-29 2014-02-27\u001b[0m\n",
      "[0.9663526244952894, 1.072570725707257, 2.858974358974359]\n",
      "\u001b[32m18004 done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "start = 18002\n",
    "end = 18005\n",
    "def trend_num(word: str, pub_time: datetime):\n",
    "    #print(pub_time)\n",
    "    y_start = str(pub_time+ timedelta(days=-15)).split(' ')[0]\n",
    "    y_end = str(pub_time + timedelta(days=14)).split(' ')[0]\n",
    "    for i in range(0, 20):\n",
    "        try:\n",
    "            y_trend = get_trend(word, y_start, y_end)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Retry step: \" + str(i))\n",
    "    \n",
    "    #print(y_trend)\n",
    "    if len(y_trend) == 30:\n",
    "        return y_trend\n",
    "    else:\n",
    "        return [0 for i in range(30)]\n",
    "    \n",
    "def trend_rate(word: str, pub_time: datetime):\n",
    "    trend = trend_num(word, pub_time)\n",
    "    now = np.sum(trend[15:])\n",
    "    #time.sleep(1)\n",
    "    past = np.sum(trend[:15])\n",
    "    #time.sleep(1)\n",
    "    if past > 0:\n",
    "        return now/past\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def export(check_point):\n",
    "    g_trend = pd.DataFrame(res)\n",
    "    g_trend.columns = [\"trend_rate\"]\n",
    "    ID = [i for i in range(start, check_point)]\n",
    "    g_trend['Id'] = ID\n",
    "    g_trend = g_trend.set_index('Id')\n",
    "    g_trend.to_csv(\"trend_%s_%s.csv\" % (str(start), str(check_point)))\n",
    "    \n",
    "res = []\n",
    "for i in range(start, end):\n",
    "    try:\n",
    "        date = get_date(dataset[\"Page content\"][i])\n",
    "        tmp = [0]\n",
    "        for cat in cats[i]:\n",
    "            print(colored(\"Search: \" + cat, \"red\"))\n",
    "            tmp.append(trend_rate(cat, date))\n",
    "        res.append(max(tmp))\n",
    "        print(res)\n",
    "        print(colored(str(i)+\" done\", \"green\"))\n",
    "        if i%10 == 0:\n",
    "            export(i+1)\n",
    "            #time.sleep(30)\n",
    "        if i == end-1:\n",
    "            export(end)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        export(i-1)\n",
    "        print(\"Break at: \" + str(i))\n",
    "        n = 0\n",
    "        print(np.mean(res))\n",
    "        for i in range(start, start+len(res)):\n",
    "            if (res[i] > float(np.mean(res))) and (1 == dataset[\"Popularity\"][i]):\n",
    "                n = n+1\n",
    "            elif (res[i] < float(np.mean(res))) and (-1 == dataset[\"Popularity\"][i]):\n",
    "                n = n+1\n",
    "            print(str(i) + \": \\t\" + str(dataset[\"Popularity\"][i]) +\"\\t\"+str(res[i]))\n",
    "        print(\"accu: \" + str(n/len(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6326325697256354\n",
      "18002: \t1\t0.9663526244952894\n",
      "18003: \t-1\t1.072570725707257\n",
      "18004: \t-1\t2.858974358974359\n",
      "accu: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "#res[1] = 2 0 o\n",
    "# [1.3623188405797102]\n",
    "# 18001 done\n",
    "n = 0\n",
    "print(np.mean(res))\n",
    "for i in range(start, start+len(res)):\n",
    "    if (res[i-18002] > float(np.mean(res))) and (1 == dataset[\"Popularity\"][i]):\n",
    "        n = n+1\n",
    "    elif (res[i-18002] < float(np.mean(res))) and (-1 == dataset[\"Popularity\"][i]):\n",
    "        n = n+1\n",
    "    print(str(i) + \": \\t\" + str(dataset[\"Popularity\"][i]) +\"\\t\"+str(res[i-18002]))\n",
    "print(\"accu: \" + str(n/len(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def export():\n",
    "#     g_trend = pd.DataFrame(res)\n",
    "#     g_trend.columns = [\"trend_rate\"]\n",
    "#     ID = [i for i in range(start, end)]\n",
    "#     g_trend['Id'] = ID\n",
    "#     g_trend = g_trend.set_index('Id')\n",
    "#     g_trend.to_csv(\"trend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"trend_%s_%s.csv\" % (str(start), str(55))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
