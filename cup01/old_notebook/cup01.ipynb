{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Page content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt; &lt;span c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Popularity                                       Page content\n",
       "0   0          -1  <html><head><div class=\"article-info\"> <span c...\n",
       "1   1           1  <html><head><div class=\"article-info\"><span cl...\n",
       "2   2           1  <html><head><div class=\"article-info\"><span cl...\n",
       "3   3          -1  <html><head><div class=\"article-info\"><span cl...\n",
       "4   4          -1  <html><head><div class=\"article-info\"><span cl..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, itertools, csv\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pytrends.request import TrendReq\n",
    "from datetime import *\n",
    "import time\n",
    "\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('./data/train.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Clara Moskowitz for Space.com 2013-06-19 15:0...</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>By Christina Warren2013-03-28 17:40:55 UTCGoog...</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>By Sam Laird2014-05-07 19:15:20 UTCBallin': 20...</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>By Sam Laird2013-10-11 02:26:50 UTCCameraperso...</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>By Connor Finnegan2014-04-17 03:31:43 UTCNFL S...</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  word_count\n",
       "0   Clara Moskowitz for Space.com 2013-06-19 15:0...         607\n",
       "1  By Christina Warren2013-03-28 17:40:55 UTCGoog...         341\n",
       "2  By Sam Laird2014-05-07 19:15:20 UTCBallin': 20...        1412\n",
       "3  By Sam Laird2013-10-11 02:26:50 UTCCameraperso...         490\n",
       "4  By Connor Finnegan2014-04-17 03:31:43 UTCNFL S...        1999"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['content'] = dataset['Page content'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "# dataset[['Page content','content']].head()\n",
    "dataset['word_count'] = dataset['content'].apply(lambda x: len(str(x).split(\" \")))\n",
    "dataset[['content','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27643.000000\n",
       "mean       609.997793\n",
       "std        495.917809\n",
       "min         37.000000\n",
       "25%        286.000000\n",
       "50%        470.000000\n",
       "75%        784.000000\n",
       "max       9551.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.word_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the       656835\n",
       "to        374557\n",
       "a         336374\n",
       "of        334089\n",
       "and       313973\n",
       "in        231056\n",
       "on        144661\n",
       "for       141448\n",
       "is        131023\n",
       "that      124579\n",
       "The       109596\n",
       "with       95561\n",
       "you        76430\n",
       "as         74429\n",
       "Image:     73433\n",
       "at         68962\n",
       "it         67840\n",
       "â€”          60907\n",
       "from       60347\n",
       "be         59647\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify common words\n",
    "freq = pd.Series(' '.join(dataset['content']).split()).value_counts()[:20]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neha prakash utctaylor swift lorde biggest fan againlorde performs american music award nov los angeles nothing say bffs eva n eva fangirling besties american music award performance amirite lorde head banging ama performance yellow flicker beat hunger game soundtrack taylor swift perfectly played part best friend see lorde compare meeting pitbull meeting president obama lorde usual exorcism meet dancing thing stage sunday bonus point smearing lipstick face taylor busy losing marble year old performance get u wrong lorde royal something work lorde taylor bow joke creativity lorde taylor swift image imgur courtesy abc image imgur courtesy abc image imgur courtesy abc image imgur courtesy abc image imgur courtesy abc image imgur courtesy abc image imgur courtesy abc image imgur courtesy abc image imgur courtesy abc image courtesy abc sure lorde dementor amas professor snape snape november lorde grim reaper energy anyone performed pettyonc edition bleushock november lorde smeared lipstick like queen amas frank gioia crankthatfrank november clubbing taylor lorde must embarrassing mel hemmo six november bonus taylor swift song sandwich window msla window loadscriptasync function src id document getelementbyid id return var j document createelement script j id id j src src document getelementsbytagname script parentnode insertbefore j fjs msla platform twitter com widget j twitter jssdk topic american music award lorde music taylor swift television video video watercooler'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries for text preprocessing\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#nltk.download('wordnet') \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\"] \n",
    "stop_words = stop_words.union(new_words)\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, dataset.shape[0]):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', dataset['content'][i])\n",
    "    text = text.lower()\n",
    "    \n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.split()\n",
    "    \n",
    "    #Lemmatisation\n",
    "    lem = WordNetLemmatizer()\n",
    "    text = [lem.lemmatize(word) for word in text if not word in  \n",
    "            stop_words] \n",
    "    text = \" \".join(text)\n",
    "    corpus.append(text)\n",
    "    \n",
    "corpus[3010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wordcloud.wordcloud.WordCloud object at 0x0000013E018410F0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "# wordcloud = WordCloud(\n",
    "#                           background_color='white',\n",
    "#                           stopwords=stop_words,\n",
    "#                           max_words=100,\n",
    "#                           max_font_size=50, \n",
    "#                           random_state=42\n",
    "#                          ).generate(str(corpus))\n",
    "# print(wordcloud)\n",
    "# fig = plt.figure(1)\n",
    "# plt.imshow(wordcloud)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "# fig.savefig(\"./data/word.png\", dpi=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clara',\n",
       " 'moskowitz',\n",
       " 'space',\n",
       " 'com',\n",
       " 'utc',\n",
       " 'nasa',\n",
       " 'grand',\n",
       " 'challenge',\n",
       " 'stop',\n",
       " 'asteroid']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "cv = CountVectorizer(max_df=0.8, stop_words=stop_words, max_features=2**20, ngram_range=(1,3))\n",
    "X = cv.fit_transform(corpus)\n",
    "list(cv.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(X)\n",
    "# get feature names\n",
    "feature_names=cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    for idx, score in sorted_items:\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "\n",
    "keyword_list = []\n",
    "\n",
    "for i in range(dataset.shape[0]):\n",
    "    doc = corpus[i]\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector = tfidf_transformer.transform(cv.transform([doc]))\n",
    "    \n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "    keywords = extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    keyword_list.append((list(keywords.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['keywords'] = keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.108, 0.103, 0.084, 0.084]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['keywords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(text: str):\n",
    "    res = list()\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    cats = soup.find_all('a', {'href': re.compile('/category/*')})\n",
    "    for cat in cats:\n",
    "        res.append(cat.get_text().lower())\n",
    "    return \" \".join(res)\n",
    "\n",
    "res = []\n",
    "for i in range(dataset.shape[0]):\n",
    "    res.append(get_category(dataset['Page content'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['category'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asteroid asteroids challenge earth space u.s. world'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['category'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "count.fit(res)\n",
    "doc_bag = count.transform(res)\n",
    "\n",
    "doc_bag = doc_bag.toarray()\n",
    "print(doc_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['category'] = list(doc_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Page content</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>keywords</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt; &lt;span c...</td>\n",
       "      <td>Clara Moskowitz for Space.com 2013-06-19 15:0...</td>\n",
       "      <td>607</td>\n",
       "      <td>[0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Christina Warren2013-03-28 17:40:55 UTCGoog...</td>\n",
       "      <td>341</td>\n",
       "      <td>[0.326, 0.326, 0.32, 0.306, 0.218, 0.205, 0.19...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Sam Laird2014-05-07 19:15:20 UTCBallin': 20...</td>\n",
       "      <td>1412</td>\n",
       "      <td>[0.414, 0.185, 0.137, 0.136, 0.077, 0.076, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Sam Laird2013-10-11 02:26:50 UTCCameraperso...</td>\n",
       "      <td>490</td>\n",
       "      <td>[0.146, 0.138, 0.093, 0.092, 0.092, 0.091, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Connor Finnegan2014-04-17 03:31:43 UTCNFL S...</td>\n",
       "      <td>1999</td>\n",
       "      <td>[0.338, 0.32, 0.104, 0.097, 0.088, 0.085, 0.07...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Popularity                                       Page content  \\\n",
       "0   0          -1  <html><head><div class=\"article-info\"> <span c...   \n",
       "1   1           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "2   2           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "3   3          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "4   4          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "\n",
       "                                             content  word_count  \\\n",
       "0   Clara Moskowitz for Space.com 2013-06-19 15:0...         607   \n",
       "1  By Christina Warren2013-03-28 17:40:55 UTCGoog...         341   \n",
       "2  By Sam Laird2014-05-07 19:15:20 UTCBallin': 20...        1412   \n",
       "3  By Sam Laird2013-10-11 02:26:50 UTCCameraperso...         490   \n",
       "4  By Connor Finnegan2014-04-17 03:31:43 UTCNFL S...        1999   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.10...   \n",
       "1  [0.326, 0.326, 0.32, 0.306, 0.218, 0.205, 0.19...   \n",
       "2  [0.414, 0.185, 0.137, 0.136, 0.077, 0.076, 0.0...   \n",
       "3  [0.146, 0.138, 0.093, 0.092, 0.092, 0.091, 0.0...   \n",
       "4  [0.338, 0.32, 0.104, 0.097, 0.088, 0.085, 0.07...   \n",
       "\n",
       "                                            category  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(dataset.shape[0]):\n",
    "    unique_rate = len(set(dataset['content'][i].split(' '))) / len(dataset['content'][i].split(' '))\n",
    "    res.append(unique_rate)\n",
    "    \n",
    "dataset['unique'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Page content</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>keywords</th>\n",
       "      <th>category</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt; &lt;span c...</td>\n",
       "      <td>Clara Moskowitz for Space.com 2013-06-19 15:0...</td>\n",
       "      <td>607</td>\n",
       "      <td>[0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.612850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Christina Warren2013-03-28 17:40:55 UTCGoog...</td>\n",
       "      <td>341</td>\n",
       "      <td>[0.326, 0.326, 0.32, 0.306, 0.218, 0.205, 0.19...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.595308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Sam Laird2014-05-07 19:15:20 UTCBallin': 20...</td>\n",
       "      <td>1412</td>\n",
       "      <td>[0.414, 0.185, 0.137, 0.136, 0.077, 0.076, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.504249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Sam Laird2013-10-11 02:26:50 UTCCameraperso...</td>\n",
       "      <td>490</td>\n",
       "      <td>[0.146, 0.138, 0.093, 0.092, 0.092, 0.091, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.493878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Connor Finnegan2014-04-17 03:31:43 UTCNFL S...</td>\n",
       "      <td>1999</td>\n",
       "      <td>[0.338, 0.32, 0.104, 0.097, 0.088, 0.085, 0.07...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.394697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Popularity                                       Page content  \\\n",
       "0   0          -1  <html><head><div class=\"article-info\"> <span c...   \n",
       "1   1           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "2   2           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "3   3          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "4   4          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "\n",
       "                                             content  word_count  \\\n",
       "0   Clara Moskowitz for Space.com 2013-06-19 15:0...         607   \n",
       "1  By Christina Warren2013-03-28 17:40:55 UTCGoog...         341   \n",
       "2  By Sam Laird2014-05-07 19:15:20 UTCBallin': 20...        1412   \n",
       "3  By Sam Laird2013-10-11 02:26:50 UTCCameraperso...         490   \n",
       "4  By Connor Finnegan2014-04-17 03:31:43 UTCNFL S...        1999   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.10...   \n",
       "1  [0.326, 0.326, 0.32, 0.306, 0.218, 0.205, 0.19...   \n",
       "2  [0.414, 0.185, 0.137, 0.136, 0.077, 0.076, 0.0...   \n",
       "3  [0.146, 0.138, 0.093, 0.092, 0.092, 0.091, 0.0...   \n",
       "4  [0.338, 0.32, 0.104, 0.097, 0.088, 0.085, 0.07...   \n",
       "\n",
       "                                            category    unique  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.612850  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.595308  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.504249  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.493878  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.394697  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekday(text: str) -> int: #input html format\n",
    "    soup = BeautifulSoup(text)\n",
    "    selector = \"time\"\n",
    "    date = [i.text for i in soup.select(selector)][0]\n",
    "    #print(soup.select(selector))\n",
    "    #print(date)\n",
    "\n",
    "    try:\n",
    "        date = date.split()\n",
    "        date = str(date[0] + ' ' + date[1])\n",
    "    #print(date)\n",
    "\n",
    "        d = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        d = d.weekday()+1\n",
    "    #print(d)\n",
    "    except:\n",
    "        d = 1\n",
    "        \n",
    "    return d\n",
    "\n",
    "res = []\n",
    "for i in range(dataset.shape[0]):\n",
    "    res.append(get_weekday(dataset['Page content'][i]))\n",
    "    \n",
    "dataset['weekday'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Page content</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>keywords</th>\n",
       "      <th>category</th>\n",
       "      <th>unique</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt; &lt;span c...</td>\n",
       "      <td>Clara Moskowitz for Space.com 2013-06-19 15:0...</td>\n",
       "      <td>607</td>\n",
       "      <td>[0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.612850</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Christina Warren2013-03-28 17:40:55 UTCGoog...</td>\n",
       "      <td>341</td>\n",
       "      <td>[0.326, 0.326, 0.32, 0.306, 0.218, 0.205, 0.19...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.595308</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Sam Laird2014-05-07 19:15:20 UTCBallin': 20...</td>\n",
       "      <td>1412</td>\n",
       "      <td>[0.414, 0.185, 0.137, 0.136, 0.077, 0.076, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.504249</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Sam Laird2013-10-11 02:26:50 UTCCameraperso...</td>\n",
       "      <td>490</td>\n",
       "      <td>[0.146, 0.138, 0.093, 0.092, 0.092, 0.091, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Connor Finnegan2014-04-17 03:31:43 UTCNFL S...</td>\n",
       "      <td>1999</td>\n",
       "      <td>[0.338, 0.32, 0.104, 0.097, 0.088, 0.085, 0.07...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.394697</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Popularity                                       Page content  \\\n",
       "0   0          -1  <html><head><div class=\"article-info\"> <span c...   \n",
       "1   1           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "2   2           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "3   3          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "4   4          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "\n",
       "                                             content  word_count  \\\n",
       "0   Clara Moskowitz for Space.com 2013-06-19 15:0...         607   \n",
       "1  By Christina Warren2013-03-28 17:40:55 UTCGoog...         341   \n",
       "2  By Sam Laird2014-05-07 19:15:20 UTCBallin': 20...        1412   \n",
       "3  By Sam Laird2013-10-11 02:26:50 UTCCameraperso...         490   \n",
       "4  By Connor Finnegan2014-04-17 03:31:43 UTCNFL S...        1999   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.10...   \n",
       "1  [0.326, 0.326, 0.32, 0.306, 0.218, 0.205, 0.19...   \n",
       "2  [0.414, 0.185, 0.137, 0.136, 0.077, 0.076, 0.0...   \n",
       "3  [0.146, 0.138, 0.093, 0.092, 0.092, 0.091, 0.0...   \n",
       "4  [0.338, 0.32, 0.104, 0.097, 0.088, 0.085, 0.07...   \n",
       "\n",
       "                                            category    unique  weekday  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.612850        3  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.595308        4  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.504249        3  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.493878        5  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.394697        4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(text: str) -> str:    \n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    title = soup.find('h1',{'class':'title'})\n",
    "    return title.get_text()\n",
    "\n",
    "res = []\n",
    "for i in range(dataset.shape[0]):\n",
    "    time = 0\n",
    "    for j in get_title(dataset['Page content'][i]).lower().split(\" \"):\n",
    "        content = dataset['Page content'][i].lower().split(\" \")\n",
    "        for k in content:\n",
    "            if j == k:\n",
    "                time = time+1\n",
    "        \n",
    "    res.append(time/dataset['word_count'][i])\n",
    "    \n",
    "dataset['title_freq'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Page content</th>\n",
       "      <th>content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>keywords</th>\n",
       "      <th>category</th>\n",
       "      <th>unique</th>\n",
       "      <th>weekday</th>\n",
       "      <th>title_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt; &lt;span c...</td>\n",
       "      <td>Clara Moskowitz for Space.com 2013-06-19 15:0...</td>\n",
       "      <td>607</td>\n",
       "      <td>[0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.612850</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Christina Warren2013-03-28 17:40:55 UTCGoog...</td>\n",
       "      <td>341</td>\n",
       "      <td>[0.326, 0.326, 0.32, 0.306, 0.218, 0.205, 0.19...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.595308</td>\n",
       "      <td>4</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Sam Laird2014-05-07 19:15:20 UTCBallin': 20...</td>\n",
       "      <td>1412</td>\n",
       "      <td>[0.414, 0.185, 0.137, 0.136, 0.077, 0.076, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.504249</td>\n",
       "      <td>3</td>\n",
       "      <td>0.042493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Sam Laird2013-10-11 02:26:50 UTCCameraperso...</td>\n",
       "      <td>490</td>\n",
       "      <td>[0.146, 0.138, 0.093, 0.092, 0.092, 0.091, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Connor Finnegan2014-04-17 03:31:43 UTCNFL S...</td>\n",
       "      <td>1999</td>\n",
       "      <td>[0.338, 0.32, 0.104, 0.097, 0.088, 0.085, 0.07...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.394697</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt; &lt;span c...</td>\n",
       "      <td>Brendan Greeley for Bloomberg 2013-11-21 18:0...</td>\n",
       "      <td>835</td>\n",
       "      <td>[0.357, 0.251, 0.208, 0.196, 0.15, 0.134, 0.12...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.586826</td>\n",
       "      <td>4</td>\n",
       "      <td>0.079042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Brian Anthony Hernandez2014-08-11 05:00:18 ...</td>\n",
       "      <td>141</td>\n",
       "      <td>[0.308, 0.308, 0.303, 0.255, 0.182, 0.182, 0.1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Sandra Gonzalez2014-11-20 00:30:41 UTCBill ...</td>\n",
       "      <td>317</td>\n",
       "      <td>[0.511, 0.246, 0.158, 0.132, 0.129, 0.112, 0.1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.646688</td>\n",
       "      <td>4</td>\n",
       "      <td>0.135647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Sara Afzal2013-09-30 04:30:01 UTCVending Ma...</td>\n",
       "      <td>319</td>\n",
       "      <td>[0.414, 0.323, 0.315, 0.267, 0.241, 0.216, 0.1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.673981</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "      <td>By Jason Abbruzzese2014-02-06 15:49:35 UTCOnli...</td>\n",
       "      <td>418</td>\n",
       "      <td>[0.295, 0.217, 0.141, 0.136, 0.133, 0.133, 0.1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.624402</td>\n",
       "      <td>4</td>\n",
       "      <td>0.057416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Popularity                                       Page content  \\\n",
       "0   0          -1  <html><head><div class=\"article-info\"> <span c...   \n",
       "1   1           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "2   2           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "3   3          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "4   4          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "5   5          -1  <html><head><div class=\"article-info\"> <span c...   \n",
       "6   6           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "7   7          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "8   8           1  <html><head><div class=\"article-info\"><span cl...   \n",
       "9   9          -1  <html><head><div class=\"article-info\"><span cl...   \n",
       "\n",
       "                                             content  word_count  \\\n",
       "0   Clara Moskowitz for Space.com 2013-06-19 15:0...         607   \n",
       "1  By Christina Warren2013-03-28 17:40:55 UTCGoog...         341   \n",
       "2  By Sam Laird2014-05-07 19:15:20 UTCBallin': 20...        1412   \n",
       "3  By Sam Laird2013-10-11 02:26:50 UTCCameraperso...         490   \n",
       "4  By Connor Finnegan2014-04-17 03:31:43 UTCNFL S...        1999   \n",
       "5   Brendan Greeley for Bloomberg 2013-11-21 18:0...         835   \n",
       "6  By Brian Anthony Hernandez2014-08-11 05:00:18 ...         141   \n",
       "7  By Sandra Gonzalez2014-11-20 00:30:41 UTCBill ...         317   \n",
       "8  By Sara Afzal2013-09-30 04:30:01 UTCVending Ma...         319   \n",
       "9  By Jason Abbruzzese2014-02-06 15:49:35 UTCOnli...         418   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.10...   \n",
       "1  [0.326, 0.326, 0.32, 0.306, 0.218, 0.205, 0.19...   \n",
       "2  [0.414, 0.185, 0.137, 0.136, 0.077, 0.076, 0.0...   \n",
       "3  [0.146, 0.138, 0.093, 0.092, 0.092, 0.091, 0.0...   \n",
       "4  [0.338, 0.32, 0.104, 0.097, 0.088, 0.085, 0.07...   \n",
       "5  [0.357, 0.251, 0.208, 0.196, 0.15, 0.134, 0.12...   \n",
       "6  [0.308, 0.308, 0.303, 0.255, 0.182, 0.182, 0.1...   \n",
       "7  [0.511, 0.246, 0.158, 0.132, 0.129, 0.112, 0.1...   \n",
       "8  [0.414, 0.323, 0.315, 0.267, 0.241, 0.216, 0.1...   \n",
       "9  [0.295, 0.217, 0.141, 0.136, 0.133, 0.133, 0.1...   \n",
       "\n",
       "                                            category    unique  weekday  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.612850        3   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.595308        4   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.504249        3   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.493878        5   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.394697        4   \n",
       "5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.586826        4   \n",
       "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.787234        1   \n",
       "7  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.646688        4   \n",
       "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.673981        1   \n",
       "9  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.624402        4   \n",
       "\n",
       "   title_freq  \n",
       "0    0.037891  \n",
       "1    0.090909  \n",
       "2    0.042493  \n",
       "3    0.010204  \n",
       "4    0.010505  \n",
       "5    0.079042  \n",
       "6    0.191489  \n",
       "7    0.135647  \n",
       "8    0.100313  \n",
       "9    0.057416  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>keywords</th>\n",
       "      <th>category</th>\n",
       "      <th>unique</th>\n",
       "      <th>weekday</th>\n",
       "      <th>title_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>607</td>\n",
       "      <td>[0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.612850</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>341</td>\n",
       "      <td>[0.326, 0.326, 0.32, 0.306, 0.218, 0.205, 0.19...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.595308</td>\n",
       "      <td>4</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1412</td>\n",
       "      <td>[0.414, 0.185, 0.137, 0.136, 0.077, 0.076, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.504249</td>\n",
       "      <td>3</td>\n",
       "      <td>0.042493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>490</td>\n",
       "      <td>[0.146, 0.138, 0.093, 0.092, 0.092, 0.091, 0.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1999</td>\n",
       "      <td>[0.338, 0.32, 0.104, 0.097, 0.088, 0.085, 0.07...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.394697</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Popularity  word_count  \\\n",
       "0   0          -1         607   \n",
       "1   1           1         341   \n",
       "2   2           1        1412   \n",
       "3   3          -1         490   \n",
       "4   4          -1        1999   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [0.463, 0.284, 0.177, 0.16, 0.124, 0.114, 0.10...   \n",
       "1  [0.326, 0.326, 0.32, 0.306, 0.218, 0.205, 0.19...   \n",
       "2  [0.414, 0.185, 0.137, 0.136, 0.077, 0.076, 0.0...   \n",
       "3  [0.146, 0.138, 0.093, 0.092, 0.092, 0.091, 0.0...   \n",
       "4  [0.338, 0.32, 0.104, 0.097, 0.088, 0.085, 0.07...   \n",
       "\n",
       "                                            category    unique  weekday  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.612850        3   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.595308        4   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.504249        3   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.493878        5   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.394697        4   \n",
       "\n",
       "   title_freq  \n",
       "0    0.037891  \n",
       "1    0.090909  \n",
       "2    0.042493  \n",
       "3    0.010204  \n",
       "4    0.010505  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = dataset.drop(columns=['Page content', 'content'])\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_csv('./data/train_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = []\n",
    "# y = []\n",
    "# for i in range(dataset.shape[0]):\n",
    "#     tmp = []\n",
    "#     tmp.append(dataset['title_freq'][i])\n",
    "#     tmp.append(dataset['weekday'][i])\n",
    "#     tmp.append(dataset['unique'][i])\n",
    "#     tmp.append(dataset['word_count'][i])\n",
    "#     tmp.extend(dataset['keywords'][i])\n",
    "#     tmp.extend(dataset['category'][i])\n",
    "#     X.append(tmp)\n",
    "#     y.append(dataset['Popularity'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
